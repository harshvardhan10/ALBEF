{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-29T21:11:39.930726Z",
     "start_time": "2025-11-29T21:11:39.700Z"
    }
   },
   "source": [
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "\n",
    "from scripts.src import (\n",
    "    build_model_and_tokenizer,\n",
    "    get_image_transform,\n",
    "    get_label_text_embeddings,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T19:00:00.101922Z",
     "start_time": "2025-11-30T19:00:00.092204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def infer_png_path(images_root, image_id):\n",
    "    png_path = images_root / f\"{image_id}.png\"\n",
    "    if png_path.exists():\n",
    "        return png_path\n",
    "    raise FileNotFoundError(f\"No PNG found for image_id={image_id} at {png_path}\")\n",
    "\n",
    "\n",
    "def get_patch_embeddings(\n",
    "    model,\n",
    "    img_tensor,\n",
    "    device,\n",
    "    patch_grid= 16,\n",
    "):\n",
    "    \"\"\"\n",
    "    img_tensor: (1, 3, H, W) on device\n",
    "    Returns:\n",
    "        patch_feats: (H', W', D) where H'=W'=patch_grid\n",
    "    \"\"\"\n",
    "    img_tensor = img_tensor.to(device, non_blocking=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        image_embeds = model.visual_encoder(img_tensor)  # (1, N+1, 768)\n",
    "        image_embeds = model.vision_proj(image_embeds)   # (1, N+1, D)\n",
    "        patch_tokens = image_embeds[:, 1:, :]            # (1, N, D)\n",
    "        patch_tokens = F.normalize(patch_tokens, dim=-1)\n",
    "\n",
    "    _, N, D = patch_tokens.shape\n",
    "    expected_N = patch_grid * patch_grid\n",
    "    if N != expected_N:\n",
    "        raise ValueError(\n",
    "            f\"Expected {expected_N} patches for grid {patch_grid}x{patch_grid}, got {N}.\"\n",
    "        )\n",
    "\n",
    "    patch_tokens = patch_tokens.view(1, patch_grid, patch_grid, D)\n",
    "    return patch_tokens.squeeze(0)  # (H', W', D)\n",
    "\n",
    "\n",
    "def compute_heatmap(\n",
    "    patch_feats,   # (H', W', D)\n",
    "    text_feat,     # (D,)\n",
    "    upsample_size,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute patchâ€“text similarity and upsample to upsample_size x upsample_size.\n",
    "    Returns heatmap as np.ndarray (H, W) in [0, 1].\n",
    "    \"\"\"\n",
    "    H, W, D = patch_feats.shape\n",
    "    text_feat = text_feat.view(1, 1, D)  # (1, 1, D)\n",
    "\n",
    "    # similarity per patch: (H, W)\n",
    "    sim = (patch_feats * text_feat).sum(dim=-1)\n",
    "    sim = (sim - sim.min()) / (sim.max() - sim.min() + 1e-6)\n",
    "\n",
    "    sim_4d = sim.unsqueeze(0).unsqueeze(0)  # (1, 1, H', W')\n",
    "    sim_up = F.interpolate(\n",
    "        sim_4d,\n",
    "        size=(upsample_size, upsample_size),\n",
    "        mode=\"bilinear\",\n",
    "        align_corners=False,\n",
    "    )\n",
    "    sim_up = sim_up.squeeze(0).squeeze(0)   # (H_up, W_up)\n",
    "\n",
    "    return sim_up.cpu().numpy().astype(np.float32)"
   ],
   "id": "61c5a3106e3275e7",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "images_root = Path(args.images_root)\n",
    "output_dir = Path(args.output_dir)\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load model/tokenizer/config once and reuse\n",
    "model, tokenizer, config, device = build_model_and_tokenizer(\n",
    "    config_path=args.config,\n",
    "    ckpt_path=args.checkpoint,\n",
    "    device=args.device,\n",
    ")\n",
    "\n",
    "image_res = config[\"image_res\"]\n",
    "transform = get_image_transform(image_res)\n",
    "\n",
    "# Load label CSV to get image_ids + label names\n",
    "df = pd.read_csv(args.labels_csv)\n",
    "id_col = df.columns[0]\n",
    "label_cols = list(df.columns[1:])\n",
    "print(f\"[Data] Found {len(df)} rows, {len(label_cols)} labels\")\n",
    "\n",
    "# For debugging a small batch\n",
    "if args.max_images is not None:\n",
    "    df = df.iloc[: args.max_images].reset_index(drop=True)\n",
    "    print(f\"[Data] Limiting to {len(df)} images (max_images={args.max_images})\")\n",
    "\n",
    "df[\"__has_png__\"] = df[id_col].apply(\n",
    "    lambda x: (images_root / f\"{x}.png\").exists()\n",
    ")\n",
    "df = df[df[\"__has_png__\"]].reset_index(drop=True)\n",
    "print(f\"[Data] After PNG filter: {len(df)} images\")\n",
    "\n",
    "image_ids = df[id_col].tolist()\n",
    "label_names = label_cols\n",
    "\n",
    "# Multi-prompt text embeddings\n",
    "label_embs = get_label_text_embeddings(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    labels=label_names,\n",
    "    device=device,\n",
    "    max_length=args.max_text_len,\n",
    ")  # (L, D)\n",
    "label_embs = label_embs.to(device)\n",
    "print(\"[Text] Label embeddings shape:\", label_embs.shape)\n",
    "\n",
    "heatmap_index_records = []\n",
    "\n",
    "for idx, image_id in enumerate(image_ids, start=1):\n",
    "    try:\n",
    "        img_path = infer_png_path(images_root, image_id)\n",
    "    except FileNotFoundError as e:\n",
    "        print(\"[WARN]\", e)\n",
    "        continue\n",
    "\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img_tensor = transform(img).unsqueeze(0)  # (1, 3, H, W)\n",
    "\n",
    "    try:\n",
    "        patch_feats = get_patch_embeddings(\n",
    "            model=model,\n",
    "            img_tensor=img_tensor,\n",
    "            device=device,\n",
    "            patch_grid=16,  # 256 / 16 = 16;\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Patch features failed for {image_id}: {e}\")\n",
    "        continue\n",
    "\n",
    "    heatmaps = {}\n",
    "    for j, label in enumerate(label_names):\n",
    "        text_feat = label_embs[j]  # (D,)\n",
    "        hmap = compute_heatmap(\n",
    "            patch_feats=patch_feats,\n",
    "            text_feat=text_feat,\n",
    "            upsample_size=image_res,\n",
    "        )\n",
    "        heatmaps[label] = torch.from_numpy(hmap)  # (H, W) tensor\n",
    "\n",
    "    out_path = output_dir / f\"{image_id}.pt\"\n",
    "    torch.save(heatmaps, out_path)\n",
    "    heatmap_index_records.append(\n",
    "        {\"image_id\": image_id, \"heatmap_path\": str(out_path)}\n",
    "    )\n",
    "\n",
    "    if idx % 50 == 0 or idx == len(image_ids):\n",
    "        print(f\"[Heatmaps] Processed {idx}/{len(image_ids)} images\")\n",
    "\n",
    "# Save index CSV\n",
    "index_df = pd.DataFrame(heatmap_index_records)\n",
    "index_path = output_dir / \"heatmap_index.csv\"\n",
    "index_df.to_csv(index_path, index=False)\n",
    "print(f\"[Output] Saved heatmap index to: {index_path}\")"
   ],
   "id": "9e87448e39c9bc82"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
