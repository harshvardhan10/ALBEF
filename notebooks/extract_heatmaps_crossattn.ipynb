{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9c98b53-6006-4172-af1d-a196594105e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to sys.path: /home/woody/iwi5/iwi5362h/ALBEF\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "#==========================================================================\n",
    "# JUPYTER PATH STUFF. Not present in the main script coz does not affect it\n",
    "# =========================================================================\n",
    "\n",
    "os.chdir(\"..\")\n",
    "\n",
    "\n",
    "root = Path().resolve()\n",
    "while root != root.parent:\n",
    "    if (root / \"scripts\").is_dir():\n",
    "        sys.path.insert(0, str(root))\n",
    "        print(\"Added to sys.path:\", root)\n",
    "        break\n",
    "    root = root.parent\n",
    "else:\n",
    "    raise RuntimeError(\"Could not find 'scripts' directory above this notebook\")\n",
    "\n",
    "from scripts.src import (\n",
    "    build_model_and_tokenizer,\n",
    "    get_image_transform,\n",
    "    get_label_text_inputs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91b23fa1-ee59-4419-a26a-e4a549781782",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.albef_crossattn_gradcam import (\n",
    "    register_albef_crossattn_gradcam_hooks,\n",
    "    remove_albef_crossattn_gradcam_hooks,\n",
    "    generate_albef_crossattn_gradcam,\n",
    ")\n",
    "from scripts.albef_gradcam import upsample_cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8a4bbde-99ae-41b9-8bf5-c46e84e9e75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_png_path(images_root: Path, image_id: str) -> Path:\n",
    "    png_path = images_root / f\"{image_id}.png\"\n",
    "    if not png_path.exists():\n",
    "        raise FileNotFoundError(f\"PNG not found for image_id={image_id}: {png_path}\")\n",
    "    return png_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f3a5dc5-1b19-4b7c-b6f9-a1d4e745202d",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_root = Path(\"/home/woody/iwi5/iwi5362h/data/vindr_cxr/test\")\n",
    "output_dir = Path(\"/home/woody/iwi5/iwi5362h/ALBEF/results/zero_shot_vindr_results/heatmaps_grad_crossattn_token_mask_layers_8_to_11\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "config_path = \"configs/Pretrain.yaml\"\n",
    "ckpt_path = \"output_mimic_a40_transformations/checkpoint_29.pth\"\n",
    "device = \"cuda\"\n",
    "labels_csv = \"/home/woody/iwi5/iwi5362h/data/vindr_cxr/annotations/image_labels_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b43ca6e0-0b56-4ea9-93ec-ea5dc413a285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model] Building ALBEF...\n",
      "[Model] State dict loaded: <All keys matched successfully>\n",
      "[CrossAttn-GradCAM] Registered hooks on cross-attention dropout for layers: [6, 7, 8, 9, 10, 11] (total 12 hooks).\n",
      "[CrossAttn-GradCAM] Hooks registered.\n"
     ]
    }
   ],
   "source": [
    "# Load model/tokenizer/config once and reuse\n",
    "model, tokenizer, config, device = build_model_and_tokenizer(\n",
    "    config_path=config_path,\n",
    "    ckpt_path=ckpt_path,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "image_res = config[\"image_res\"]\n",
    "\n",
    "transform = get_image_transform(image_res)\n",
    "model.eval()\n",
    "\n",
    "# ---- Register Grad-CAM hooks ----\n",
    "handles = register_albef_crossattn_gradcam_hooks(model)\n",
    "print(\"[CrossAttn-GradCAM] Hooks registered.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e88350b-0833-41c3-b242-bf6bc886ce41",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_images = 100\n",
    "only_labels = [\"Pleural effusion\", \"Cardiomegaly\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce4e2f3b-8cfa-4887-821e-3370e2cb6095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Data] 3000 rows, 28 labels in CSV.\n",
      "[Data] After PNG filter: 100 images remain.\n",
      "[Data] Restricting to labels: ['Pleural effusion', 'Cardiomegaly']\n"
     ]
    }
   ],
   "source": [
    "# ---- Load CSV & determine labels ----\n",
    "df = pd.read_csv(labels_csv)\n",
    "id_col = df.columns[0]\n",
    "all_label_cols = list(df.columns[1:])\n",
    "print(f\"[Data] {len(df)} rows, {len(all_label_cols)} labels in CSV.\")\n",
    "\n",
    "if max_images is not None:\n",
    "    df = df.iloc[: max_images].reset_index(drop=True)\n",
    "\n",
    "def has_png(row):\n",
    "    return (images_root / f\"{row[id_col]}.png\").exists()\n",
    "\n",
    "df[\"__has_png__\"] = df.apply(has_png, axis=1)\n",
    "df = df[df[\"__has_png__\"]].reset_index(drop=True)\n",
    "print(f\"[Data] After PNG filter: {len(df)} images remain.\")\n",
    "\n",
    "image_ids = df[id_col].tolist()\n",
    "label_cols = all_label_cols\n",
    "\n",
    "if only_labels is not None:\n",
    "    missing = [lb for lb in only_labels if lb not in label_cols]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Requested labels not in CSV: {missing}\")\n",
    "    label_cols = only_labels\n",
    "    print(f\"[Data] Restricting to labels: {label_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83e0f9bc-b37f-415b-8113-1a8184a51f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Precompute text inputs per label ----\n",
    "input_ids_dict, attn_mask_dict, token_mask_dict = get_label_text_inputs(\n",
    "    tokenizer=tokenizer,\n",
    "    labels=label_cols,\n",
    "    max_length=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19f9900e-4b17-4524-97ee-9fd4bdfa2d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CrossAttn-GradCAM] Processed 20/100 images\n",
      "[CrossAttn-GradCAM] Processed 40/100 images\n",
      "[CrossAttn-GradCAM] Processed 60/100 images\n",
      "[CrossAttn-GradCAM] Processed 80/100 images\n",
      "[CrossAttn-GradCAM] Processed 100/100 images\n",
      "[Output] Saved cross-attn Grad-CAM index to: /home/woody/iwi5/iwi5362h/ALBEF/results/zero_shot_vindr_results/heatmaps_grad_crossattn_token_mask_layers_8_to_11/crossattn_gradcam_index.csv\n",
      "[CrossAttn-GradCAM] Hooks removed and buffers cleared.\n",
      "[CrossAttn-GradCAM] Hooks removed.\n"
     ]
    }
   ],
   "source": [
    "# ---- Process images ----\n",
    "index_records = []\n",
    "for idx_img, image_id in enumerate(image_ids, start=1):\n",
    "    try:\n",
    "        img_path = infer_png_path(images_root, image_id)\n",
    "    except FileNotFoundError as e:\n",
    "        print(\"[WARN]\", e)\n",
    "        continue\n",
    "\n",
    "    img_pil = Image.open(img_path).convert(\"RGB\")\n",
    "    img_tensor = transform(img_pil).unsqueeze(0)  # (1,3,H,W)\n",
    "\n",
    "    heatmaps = {}\n",
    "    for label in label_cols:\n",
    "        input_ids = input_ids_dict[label]      # (1,T)\n",
    "        attn_mask = attn_mask_dict[label]      # (1,T)\n",
    "        text_token_mask = token_mask_dict[label]\n",
    "\n",
    "        cam_patch = generate_albef_crossattn_gradcam(\n",
    "            model=model,\n",
    "            img_tensor=img_tensor,\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attn_mask,\n",
    "            device=device,\n",
    "            text_token_mask=text_token_mask,\n",
    "            layers_to_use=[8, 9, 10, 11]  # trying last 4 instead of all 6\n",
    "        )\n",
    "\n",
    "        cam_up = upsample_cam(cam_patch, target_size=image_res)\n",
    "        heatmaps[label] = cam_up\n",
    "\n",
    "    out_path = output_dir / f\"{image_id}.pt\"\n",
    "    heatmaps_cpu = {k: v.float().cpu() for k, v in heatmaps.items()}\n",
    "    torch.save(heatmaps_cpu, out_path)\n",
    "    index_records.append({\"image_id\": image_id, \"heatmap_path\": str(out_path)})\n",
    "\n",
    "    if idx_img % 20 == 0 or idx_img == len(image_ids):\n",
    "        print(f\"[CrossAttn-GradCAM] Processed {idx_img}/{len(image_ids)} images\")\n",
    "\n",
    "index_df = pd.DataFrame(index_records)\n",
    "index_path = output_dir / \"crossattn_gradcam_index.csv\"\n",
    "index_df.to_csv(index_path, index=False)\n",
    "print(f\"[Output] Saved cross-attn Grad-CAM index to: {index_path}\")\n",
    "\n",
    "remove_albef_crossattn_gradcam_hooks(handles)\n",
    "print(\"[CrossAttn-GradCAM] Hooks removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e849f8b-df51-4446-b671-8ef85259381c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "albef-env",
   "language": "python",
   "name": "albef-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
